\documentclass[a4paper,12pt]{report}
\usepackage{graphicx}  % For including graphics
\usepackage{hyperref}  % For hyperlinks
\usepackage{listings}  % For code snippets
\usepackage{tocbibind} % For adding ToC to the table of contents
\usepackage{titlesec}  % For customizing titles
\usepackage[ngerman]{babel}
\usepackage{wasysym}
\usepackage{parskip}
\usepackage{bm}
\usepackage{xcolor}

\lstset{
    backgroundcolor=\color{black}, % Black background
    basicstyle=\ttfamily\small\color{white}, % Monospace font, white text
    frame=single, % Box around the code
    rulecolor=\color{gray}, % Border color
    breaklines=true, % Allow breaking long lines
    showstringspaces=false, % Don't show spaces as symbols
    xleftmargin=5pt, % Margin for padding
    xrightmargin=5pt
}


\usepackage{geometry}
\usepackage{booktabs}
\geometry{
    top=1in,
    left=1in,
    right=1in,
    bottom=1in
}


\titleformat{\chapter}[block]   % Set chapter format to block style (both on same line)
{\normalfont\huge\bfseries}     % Format for the chapter number and title
{\thechapter}                   % Shows the chapter number followed by a dot
{0.5em}                         % Space between the chapter number and title
{}                              % Formatting for the chapter title (leave empty)

\renewcommand{\contentsname}{Inhaltsverzeichnis}
\renewcommand{\listtablename}{Tabellenverzeichnis}
\renewcommand{\listfigurename}{Abbildungsverzeichnis}
\renewcommand{\lstlistlistingname}{Code-Ausschnitte}
\renewcommand{\abstractname}{Zusammenfassung}
\renewcommand{\chaptername}{Kapitel}

\begin{document}

% Title Page
    \begin{titlepage}
        \centering
        \textit{Berner Fachhochschule}\\[0.2em]
        \textit{BTI3031 Project 1}
        \vfill
        {\huge \textbf{AI-Aided Caches-n-Logs Monitoring-n-Wiping Daemon}}\\[4em]
        {\large Luca Scherer, Janic Scherer, Luca Ammann }\\[0.5em]
        \begin{tabular}{ll}
            \textbf{Betreuer:}\hspace{0.5em}Dr. Simon Kramer \\
        \end{tabular}

        \vfill
        \textit{\today}
    \end{titlepage}

% Abstract
    \begin{abstract}
        \ldots
    \end{abstract}

% Table of Contents
    \tableofcontents
    \listoftables
    \listoffigures
    \lstlistoflistings

% Main Content


    \chapter{Einleitung}


    \section{Ausgangssituation}

    \subsection{Problem}\label{subsec:problem}
    Cache- und Logdateien sind temporäre Dateien, die von Betriebssystemen und
    Anwendungen zur Speicherung von Zwischenständen, Nutzeraktivitäten und
    Systemereignissen erstellt werden.
    Viele Computerbenutzer sind sich nicht bewusst, welche Arten dieser Dateien auf ihrem
    Computer existieren und insbesondere, welche Applikationen diese lesen, schreiben,
    verändern oder löschen.
    Dazu sind sich Anwender nicht bewusst, welchen Zwecken
    diese Dateien dienen und welche möglicherweise vertrauliche Informationen enthalten,
    die für Dritte von Interesse sein könnten.
    Diese Unkenntnis kann zu Datenschutzrisiken
    und fehlender Kontrolle führen.

    \subsection{Chance}\label{subsec:chance}
    Durch das Angebot an generativen KI-Modellen, die – meist frei oder relativ günstig - im
    Internet zugänglich sind, lässt sich schnell Fachkenntnis zu solchen Dateien einholen.
    Betrachtet werden hierbei vor allem die Struktur (Syntax) und Bedeutung (Semantik) von Dateiinhalten.
    Des Weiteren lassen sich Schlüsse aus Änderungen, Löschungen und Neuerstellungen von Dateien ziehen.\footnote{Evalutation durch KI-Modell in Bezug auf die Bedeutung von Änderungen, Löschungen und Neuerstellungen nicht weiter realisiert, siehe Kapitel \nameref{sec:zukunftigearbeiten}.}
    Durch das automatisierte Abfragen dieser KI-Modelle in einer eigenen Anwendung,
    welche unter anderem Momentaufnahmen (sogenannte\ Snapshots) relevanter Dateipfaden und Metadaten speichert,
    sowie weitere Mehrwerte in Bezug auf die Nutzererfahrung realisiert, kann einem
    Benutzer auf einfache Art und Weise die Möglichkeit zur Kontrolle und Erleichterung dieses Umstandes
    geboten werden.

    \subsection{Antrag}\label{subsec:stakeholder}
    Das Projekt-Proposal umfasst einerseits die Entwicklung einer Software, welche die besagten Anforderungen erfüllt,
    andererseits das Ermitteln des Potentials aktueller KI-Modelle zur Lösung des genannten Problems.\\
    Einziger Stakeholder ist Simon Kramer als Betreuer und Auftraggeber.\\


    \section{Projektziel}\label{sec:projektziel}
    Es soll eine Anwendung entwickelt werden, welche die \textbf{Suche, Überwachung und Löschung von Cache- und Logdateien} ermöglicht.
    Dazu gehört das \textbf{Einholen von Einschätzungen eines KI-Modells}, welches die Dateien analysiert und bewertet.
    Die Applikation soll \textbf{plattformunabhängig}, \textbf{benutzerfreundlich} und mit der nötigen \textbf{Dokumentation} für den Benutzer (User-Manual u.a.) ausgestattet sein.
    \\Das AI-Modell wird nur abgefragt bzw.\ eingebunden und dessen Entwicklung und Betrieb
    wird vom Projekt abgegrenzt.
    Passend zu dieser Abgrenzung soll als Komponente des Berichts das Potential von KI-Modellen bzw.\ des eingesetzten KI-Modells zur Lösung des Problems evaluiert werden.


    \section{Prioritäten}
    Grundsätzlich soll ein fertiges Produkt, welches dem Benutzer einen Mehrwert bietet, im Vordergrund stehen.
    Gemäss Checkliste (via Mail von Simon Kramer am 26.09.2024):
    \begin{quote}
        Resultat- statt Prozess-Orientierung priorisieren:
        \\Fertiges Projekt anstreben (Prozesse, die unfertige Resultate produzieren, vermeiden)
        \\Programme sind bessere Modelle (Spezifikations- und Design-Endlosschlaufen vermeiden)
    \end{quote}

    Priorisiert sollen dabei in erster Linie Funktionalitäten eines MVP (Minimum Viable Product) sein, welche die Kernfunktionalität des Produkts sicherstellen.
    Dazu gehören vor allem die Suche und Überwachung von Dateien.
    Zur Überwachung gehört das Erstellen von Snapshots und das Vergleichen dieser, sowie das Einholen von Einschätzungen eines KI-Modells.
    Zudem werden alle Tätigkeiten, die dabei mitschwingen, wie Dokumentation, Tests und Codequalität, als wichtig erachtet.
    Zurückpriorisierte Funktioalitäten, sowie Erweiterungen werden im Kapitel \nameref{sec:zukunftigearbeiten} beschrieben.


    \chapter{Spezifikation}
    \section{Systemabgrenzung}
    \subsection{Systemumgebung}
    \subsubsection{Systemübersicht}
    Der Hauptverwendungszweck des TraceSentry ist das Überwachen von Dateien in einem bestimmten Verzeichnis.
    Dabei liegt der Fokus auf Log- und Cache-Dateien, welche auf Änderungen in Form von Erstellung, Löschung oder Veränderung überprüft werden.
    Diese Überprüfung erfolgt in einem Hintergrundprozess (Daemon), welcher autonom und periodisch die Dateien überwacht.
    Die Resultate dieser Überwachung sollen persistiert und dem Benutzer über eine Benutzerschnittstelle zugänglich gemacht werden.
    Der Benutzer hat zusätzlich die Möglichkeit, nach Dateien zu suchen, um sinnvolle Verzeichnisse für die Überwachung zu finden.
    Findet der Benutzer eine für ihn interessante Datei durch die Suche oder Überwachung, kann er eine Inspektion dieser Datei anfordern.
    Dabei soll ein KI-Modell die Datei analysieren und eine Einschätzung abgeben, ob die Datei schädlich ist und wie damit umgegangen werden sollte.
    Ebenfalls über die Benutzerschnittstelle kann der Benutzer Dateien leeren oder löschen, insofern es für Ihn oder das KI-Modell sinnvoll erscheint.


    \clearpage
    \subsection{Prozessumgebung}

    \clearpage
    \section{Anforderungen}
    Die Anforderungen für den AI-Aided Caches-n-Logs Monitoring-n-Wiping Demon ergaben sich aus dem Projekt Proposal sowie einem initialen Termin mit Herr Kramer.

    \subsection{Funktionale Anforderungen}

    Alle funktionalen Anforderungen werden in Form von User Stories im Scrum Product Backlog geführt. Dieser wird laufend erweitert beziehungsweise konkretisiert. Eine User Story gilt erst als abgeschlossen, sobald alle dazugehörende Akzeptanzkriterien erfüllt sind. Folgende funktionale Anforderungen wurden definiert und in User Stories inkl. Akzeptanzkriterien abgebildet:
    \begin{itemize}
        \item Das System findet jegliche Log- oder Cache-Dateien, welche sich in einem angegebenen Verzeichnis befinden. Dabei werden auch alle Unterverzeichnisse berücksichtigt.
        \item Das System durchsucht periodisch angegebene Verzeichnisse inkl. Unterverzeichnisse nach Log- oder Cache-Dateien.
        \item Das System erstellt periodisch sogenannte Snapshots der gefundenen Dateien, um diese später miteinerander zu vergleichen.
        \item Das System identifiziert veränderte Dateien anhand der periodisch erstellten Snapshots.
        \item Das System kann den Verwendungszweck von angegebenen Dateien erkennen und nach folgenden Merkalen kategorisieren oder bewerten:
        \begin{itemize}
            \item Dateityp
            \item Verwendungszweck
            \item Schädlichkeit
            \item Leer- bzw. löschbar
        \end{itemize}
        \item Das System kann angegebene Dateien, nach einer Bestätigung des Benutzers leeren oder löschen.
    \end{itemize}
    TODO: Backlog einbinden/beschreiben

    \newpage

    \subsection{Grenz- und Vorbedingungen}
    Im Scrum Product Backlog werden nichtfunktionalen Anforderungen bzw. Grenz- oder Vorbedingungen nicht explizit als User Story geführt. Aus dem Projekt-Proposal und dem initialen Termin ergaben sich nachfolgende nichtfunktionale Anforderungen.
    Diese beeinflussten massgeblich die Architektur des Systems. Keine User Story darf eine oder mehrere nichtfunktionale Anforderungen verletzten, was durch die Definition of Done sichergestellt und laufend geprüft wird.

    \begin{table}[h!]
        \centering
        \setlength{\leftmargini}{0.4cm}
        \begin{tabular}{|c|p{10cm}|}
            \hline
            \textbf{ID}           & NFR-001                                                                                            \\ \hline
            \textbf{Anforderung}  & Hintergrundprozess mit periodischem Task (deamon)                                                  \\ \hline
            \textbf{Beschreibung} & Das System muss einen Hintergrundprozess implementieren, der periodisch Aktionen durchführen kann. \\ \hline
            \textbf{Akzeptanzkriterien} &
            \begin{itemize}
                \item Nach dem Start des Prozesses, ist dieser für den Benutzer nicht mehr ersichtlich.
                \item Der Hintergrundprozess ist erweiterbar, sodass dieser periodisch und autonom Aktionen durchführen kann.
            \end{itemize}
            \\ \hline
        \end{tabular}
        \caption{Nichtfunktionale Anforderung NFR-001}\label{tab:nfr-1}
    \end{table}

    \begin{table}[h!]
        \centering
        \setlength{\leftmargini}{0.4cm}
        \begin{tabular}{|c|p{10cm}|}
            \hline
            \textbf{ID}           & NFR-002                                                              \\ \hline
            \textbf{Anforderung}  & Benutzerschnittstelle via Konsole (CLI)                              \\ \hline
            \textbf{Beschreibung} & Mit dem laufenden deamon soll via Konsole interagiert werden können. \\ \hline
            \textbf{Akzeptanzkriterien} &
            \begin{itemize}
                \item Der deamon kann via CLI gestartet werden.
                \item Alle Konfigurationen und Aktionen des deamon sind via CLI verfügbar
            \end{itemize}
            \\ \hline
        \end{tabular}
        \caption{Nichtfunktionale Anforderung NFR-002}\label{tab:table4}
    \end{table}

    \begin{table}[h!]
        \centering
        \setlength{\leftmargini}{0.4cm}
        \begin{tabular}{|c|p{10cm}|}
            \hline
            \textbf{ID}           & NFR-003                                                                 \\ \hline
            \textbf{Anforderung}  & Systemunabhängigkeit                                                    \\ \hline
            \textbf{Beschreibung} & Lauffähigkeit mit vollem Funktionsumfang auf gängigen Betriebssystemen. \\ \hline
            \textbf{Akzeptanzkriterien} &
            \begin{itemize}
                \item Hintergrundprozess sowie Konsolenschnittstelle sind auf allen gängigen Betriebssystemen lauffähig und mit vollem Funktionsumfang verwendbar.
                \item Neuimplementierte Features werden auf aktuellen Versionen von Windows, Linux (Ubuntu) und MacOS getestet.
            \end{itemize}
            \\ \hline
        \end{tabular}
        \caption{Nichtfunktionale Anforderung NFR-003}\label{tab:table5}
    \end{table}

    \begin{table}[h!]
        \centering
        \setlength{\leftmargini}{0.4cm}
        \begin{tabular}{|c|p{10cm}|}
            \hline
            \textbf{ID}           & NFR-004                                        \\ \hline
            \textbf{Anforderung}  & Codequalität \& erweiterbare Architektur       \\ \hline
            \textbf{Beschreibung} & Minimaler, modularer und selbserklärender Code \\ \hline
            \textbf{Akzeptanzkriterien} &
            \begin{itemize}
                \item Die Architketur wird so aufgebaut, dass neue Features problemlos ergänzt werden können. (z.B. GUI)
                \item Tests gemäss Testkonzept.
                \item Statische Analysen zeigen keine schwerwiegenden verstösse gegen Linting-Regeln.
                \item Anwendungen von gängigen Design-Prinzipen vie SOLID, DRY, KISS etc.
                \item Für jede Codeerweiterung wird eine Codereview durch einen zweiten Entwickler vorgenommen.
            \end{itemize}
            \\ \hline
        \end{tabular}
        \caption{Nichtfunktionale Anforderung NFR-004}\label{tab:table6}
    \end{table}

    \clearpage

    \subsection{Testkonzept}

    \subsubsection{Ziel des Testkonzepts}
    \begin{itemize}
        \item Sicherstellen, dass das gesamte System stabil läuft und seine Hauptfunktionen zuverlässig verfügbar sind.
        \item Minimales Testing-Setup, das nur dort Unit-Tests verwendet, wo es Sinn ergibt (z. B. kritische Algorithmen), um den Entwicklungsaufwand gering zu halten.
        \item Fokus auf Integrationstests und funktionale Tests zur Überprüfung der gesamten Systemfunktionalität.
        \item Klare Definition, welche Tests während der Entwicklung (Teil einer User Story) umgesetzt werden sollen.
    \end{itemize}

    \subsubsection{Testarten und Testabdeckung}
    \begin{itemize}
        \item \textbf{Unit-Tests}: Nur für kritische, isolierbare Logiken wie:
        \begin{itemize}
            \item \textbf{Hash-Algorithmen}: Test der Konsistenz und Korrektheit, insbesondere, wenn Hashes fürs Verzeichnis Monitoring verwendet werden.
            \item \textbf{File-Suche}: Suchalgorithemen für Log- oder Cache-Dateien.
        \end{itemize}
        \item \textbf{Integrationstests}: Testen der Zusammenarbeit mehrerer Komponenten.
        \begin{itemize}
            \item \textbf{CLI-Befehle}: Überprüfen, dass die CLI-Kommandos (\texttt{run}, \texttt{search}) korrekt ausgeführt werden und die erwarteten Parameter validieren.
            \item \textbf{REST-HTTP-Anfragen}: Testen, ob alle HTTP-Schnittstellen korrekt reagieren. (Happy- sowie Exception-Paths)
        \end{itemize}
        \item \textbf{End-to-End Tests}: Fokus auf End-to-End-Szenarien zur Validierung der zentralen Funktionalität.
    \end{itemize}

    \subsubsection{Test-Setup und -Konfiguration}
    \begin{itemize}
        \item \textbf{Mocking von Ressourcen}: Verwenden von Mocks für Datenbank- und Dateisystemzugriffe in den Unit-Tests, um sie isoliert zu halten.
        \item \textbf{Testumgebung}: Erstellen einer dedizierten Test-DB und eines Testverzeichnisses.
        \item \textbf{Automatisierte Testausführung}: Integration der Tests in die CI/CD-Pipeline, um sicherzustellen, dass das System stabil bleibt.
    \end{itemize}

    \clearpage


    \section{Usability}\label{sec:usability}

    \subsection{Personas}\label{subsec:personas}

    \subsubsection{Thomas}

    \begin{figure}[h]
        \centering
        \includegraphics[width=0.6\textwidth]{assets/persona1}
        \caption{Thomas \footnote}
        \label{fig:persona-1}
    \end{figure}

    Thomas ist ein 35-Jähriger Berufsschullehrer, der Informatiker und Elektroniker unterrichtet.
    Für seine Schüler unterrichtet er unter anderem auch
    Systemadministration und IT-Sicherheit.
    Thomas ist sehr interessiert an neuen Technologien und probiert gerne neue Software aus.
    Daher stellt er sich die Frage, warum so viele Log- und Cache-Dateien auf seinem Rechner sind, ob diese alle
    ihre Daseinsberechtigung haben und auch ob das Lesen und Schreiben dieser Dateien nicht ein Sicherheitsrisiko
    darstellt.
    Thomas ist ein sehr erfahrener Benutzer und hat keine Probleme mit der Kommandozeile.

    \begin{table}[h!]
        \centering
        \setlength{\leftmargini}{0.4cm}
        \begin{tabular}{|p{2.5cm}|p{7cm}|}
            \hline
            \textbf Aufgaben    & KnowHow stärken (in Bezug auf seine Lehrtätigkeiten)                      \\
            \hline
            \textbf Ziele       & Veränderungen beobachten können und diese überprüfen lassen               \\
            \hline
            \textbf Wünsche     & Intuitive Benutzerschnittstelle und teilweise Automatisierung             \\
            \hline
            \textbf Hindernisse & Trotz Erfahrung in der Informatik, sind teilweise Wissenslücken vorhanden \\
            \hline
        \end{tabular}
        \label{tab:table7}
    \end{table}

    \footnotetext{\url{https://www.pexels.com/de-de/foto/mann-arbeiten-tippen-pc-16129724/}.}


    \newpage

    \subsection{Storyboard}
    In diesem Abschnitt wird beschrieben, wie ein Nutzer mit den verschiedenen Funktionen der Software
    interagieren kann.
    Dafür haben wir folgend eine sinnvolle Abfolge zusammengestellt, wie ein Nutzer
    unsere Software in einem realen Anwendungsfall verwenden könnte.

    \begin{enumerate}
        \item \textbf{Dateien suchen}\\
        Der Nutzer hat kürzlich in seinem Task-Manager ein Programm entdeckt, das komischerweise
        ziemlich viel Speicher braucht.
        Also verwendet er unseren search-Befehl mit dem Pfad auf die Installation von diesem Programm
        und ihm werden die in diesem Verzeichnis gefundenen Cache- sowie Log-Dateien aufgelistet:
        \begin{verbatim}
internal/test.log
internal/cache.json
        \end{verbatim}

        \item \textbf{Dateien überwachen}\\
        Nun möchte der Nutzer dieses Verzeichnis \texttt{/internal} innnerhalb des Programmverzeichnisses genauer überwachen.
        Also fügt er diesen Pfad mit dem monitor-Befehl hinzu und schon wird dieses Verzeichnis vom TraceSentry stündlich überwacht.

        \item \textbf{Snapshots vergleichen}\\
        Nach einigen Stunden möchte nun der Nutzer wissen was in diesem überwachten Verzeichnis passiert ist.
        Dafür nutzt er den snapshot compare-Befehl, um alle Zustände des Verzeichnisses vom aktuellen Zeitpunkt bis zum Start der Überwachung vergleichen zu können.
        Das System gibt ihm eine entsprechende Ausgabe:
        \begin{verbatim}
Vergleich vom Verzeichnis /internal
vom Zeitpunkt 01.12.2024 15:00:00 bis zum Zeitpunkt 01.12.2024 22:00:00:

test.log CHANGED 7-times
        \end{verbatim}

        \item \textbf{KI-Abfrage für eine Datei}\\
        Nun möchte der Nutzer natürlich wissen, wofür diese test.log Datei ist, wenn sich diese jede Stunden ändert.
        Also nutzt er den inspect-Befehl, um die angebundene KI abzufragen, wofür diese Datei genau ist, ob sie ein Sicherheitsrisiko darstellt
        und ob er die Datei evtl. leeren oder sogar löschen kann.
        Daraus kommt dann eine standardisierte Ausgabe von der KI:
        \begin{verbatim}
Die Datei ist unbekannt für dieses Programm und deswegen potenziell
schädlich, also empfehle ich es zu leeren.
        \end{verbatim}

        \item \textbf{Datei leeren oder löschen}\\
        Zum Schluss kann der Nutzer dann selbst entscheiden was er mit dieser Information anfangen möchte.
        In diesem Fall möchte er dem Ratschlag der KI folgen und die Datei leeren.
        Also nutzt er den wipe-Befehl mit dem Pfad der test.log Datei und das System leert die Datei wie gewünscht.
    \end{enumerate}

    \newpage

    \subsection{UX-Prototyping}
    Da wir nur ein Command-Line-Interface haben, decken wir dieses Kapitel bereits mit
    der Dokumentation dieser Schnittstelle ab, welche im folgenden Kapitel \hyperref[sec:user-manual]{Benutzerhandbuch} vorhanden ist.
    Dort werden alle Befehle mit ihrer Struktur und auch ihren Parametern genau beschrieben.
    Dazu werden auch Anwendungsbeispiele mit den möglichen Systemantworten erläutert.


    \chapter{Implementierung}


    \section{Performanz und Optimierung}

    \subsection{Komplexität}

    Unser System ist von Grund auf auf Effizienz und Performanz ausgelegt, der Hashbaum als zentrale Datenstruktur ermöglicht dies.
    Die Datenmenge mit der ein Benutzer arbeitet, kann sehr gross werden, daher ist es wichtig, dass die Skalierbarkeit des Systems gewährleistet ist.
    Daher ist eine Analyse der Komplexität der verschiedenen Operationen angebracht.
    \\
    Jeder Ordner und jede Datei wird als Knoten im Hashbaum repräsentiert.
    Die Wurzel des Hashbaums repräsentiert den zu überwachenden Pfad.
    Dateien sind stets Blätter.\newline
    Sei $n$ die Anzahl der Knoten im Verzeichnis des zu überwachenden Pfades.

    \paragraph{Bau}
    Der Baualgorithmus besucht rekursiv alle Dateien und Ordner im zu überwachenden Pfad,
    was einer Komplexität von $O(n)$ für das Traversieren entspricht.
    Das Hashen eines Ordners mit $k$ Kindern setzt eine Iteration über alle Kinder voraus, was einer Komplexität von $O(k)$ entspricht.
    Das Hashen eines Blattes (Datei) ist abhängig von der Grösse $s$ der Datei und hat eine Komplexität von $O(s)$.
    \\\\
    Die Gesamtkomplexität des Bauens des Hashbaums beträgt also \boldsymbol{$O(n * s)$}
    Hier ist $s$ die durchschnittliche Dateigrösse. $k$ ist implizit in $n$ enthalten.

    \paragraph{Linearisierung}
    Es gibt Fälle, in denen der Hashbaum linearisiert wird, um z.B.\ die Java Stream API zu verwenden oder direkt alle Knoten miteinander zu persisitieren.
    Es werden für alle Knoten die Referenzen in einer Liste gespeichert, was einer Komplexität von  \boldsymbol{$O(n)$} entspricht.

    \subsection{Caching}
    Bei den folgenden zwei Fällen haben wir uns überlegt, ob es sich lohnen würde, ein Caching einzubauen,
    haben uns dann aber aus den aufgelisteten Gründen dagegen entschieden.

    \begin{enumerate}
        \item Pro MonitoredPath könnte man immer den letzten gebauten MerkleTree cachen, um beim nächsten Snapshot
        direkt mit dem gecachten Baum verlgeichen zu können, ohne diesen wieder aus der Datenbank laden zu müssen.
        \begin{itemize}
            \item Caching macht nur Sinn wenn mehrmals die gleichen Daten gelesen werden.
            Da aber der MerkleTree vom letzten Snapshot nur einmal wiederverwendet wird (beim Vergleichen mit dem Neuen), macht dies hier keinen Sinn.
            \item Kein sich lohnender Mehrwert an Performance gegenüber dem Laden aus der DB, da die DB lokal ist und die Query
            eine tiefe Komplexität hat, kann bereits effizient auf die Daten zugegriffen werden.
        \end{itemize}
        \item Pro MonitoredPath eine geordnete Liste nur mit den Änderungen von jedem Snapshot, damit diese bei der Abfrage
        direkt aus dem Memory zurückgegeben werden können und nicht noch die DB abgefragt werden muss.
        \begin{itemize}
            \item Auch hier wird keine sich lohnende Performance-Steigerung erwartet, denn auch wenn die Daten schon in Memory wären
            braucht es für die zusammengefasste Response der abgefragten Vergleiche trotzdem noch Logik,
            welche auch mit einem Query auf die lokale DB implementiert werden kann und so kein grosser Gewinn daraus resultiert.
        \end{itemize}
    \end{enumerate}

    \subsection{Indexing}
    Anhand der folgenden Punkte wurde entschieden, ob/für welche Attribute in der DB ein SQL-Index sinnvoll wäre.

    Index sinnvoll:
    \begin{itemize}
        \item Attribut hat viele verschiedene Werte
        \item Attribut hat wenige/keine null-Werte
        \item Attribut wird oft in einer SQL WHERE oder JOIN Abfrage genutzt
    \end{itemize}

    Index nicht sinnvoll:
    \begin{itemize}
        \item kleine Tabelle
        \item Attribut wird oft manipuliert
    \end{itemize}

    So wurde entschieden die folgenden Attribute zu indexieren:
    \begin{itemize}
        \item \verb|snapshot_node.snapshot_id|
        \item \verb|snapshot_node.has_changed|
        \item \verb|snapshot_node.deleted_in_next_snapshot|
    \end{itemize}


    \section{Architektur}

    \subsection{Architekturentscheid}
    In diesem Abschnitt soll erläutert werden, was wir uns für Gedanken bezüglich der Architektur gemacht haben
    und für was wir uns schlussendlich aus welchen Gründen entschieden haben.

        {\large\bfseries Daemon}

    Als erstes war uns aus den Anforderungen klar, dass wir einen Daemon brauchen, also ein Programm, welches immer im
    Hintergrund (seit Start des Computers) laufen soll.
    Also muss das bereits ein eigenständiges Programm sein, das z.B. beim Systemstart (Autostart bei Windows) ausgeführt werden kann.

        {\large\bfseries Database}

    Als nächstes gibt es die Anforderung, dass Pfad-Analysen zu einem späteren Zeitpunkt verglichen werden können sollen.
    So war für uns auch klar, dass wir eine Datenbank (DBMS) brauchen.
    Dazu haben wir verschiedene Varianten:

    \textbf{1. In-Memory}
    In diesem Fall würde die Datenbank mit dem Start des Programms mitinitialisiert und beim Beenden des Programms auch wieder gelöscht.
    Das bedeutet die Datenbank lebt nur während der Laufzeit des Programms und braucht auch den Speicher des Programms mit.

    \textbf{Begründung zur Variante In-Memory} Diese kommt für uns nicht in Frage, da wir die Analysen auch über die Laufzeit des Daemons hinaus persistieren möchten.
    Damit der Anwender beispielsweise auch nach einem Neustart noch Zugriff auf seine früheren Datei-Analysen hat.

    \textbf{2. Embedded}
    Hier wird die Datenbank in Form von Files innerhalb des Programms (Programm-Ressourcen) mitgeliefert und bleibt
    somit persistent solange es nicht gelöscht wird im Verzeichnis des Programms.

    \textbf{Vorteile}
    \begin{itemize}
        \item Braucht keine externe Infrastruktur
        \item Offline-Verfügbarkeit
        \item Performance
    \end{itemize}

    \textbf{Nachteile}
    \begin{itemize}
        \item Datenverlust bei einem Problem des Anwender-Systems
    \end{itemize}

    \textbf{Begründung zur Variante Embedded} Diese Variante passt für unseren Use-Case am Besten, da wir nur ein kleines System entwickeln.
    Dadurch brauchen wir keine grosse Kapazität an Speicher.
    Die Datenbank ist ebenso einfach und schnell eingerichtet und benötigt keine weitere Infrastruktur.
    Die Verantwortung der Datenbank liegt somit nicht bei uns, sondern beim Anwender.
    Dazu streben wir an, unser System vorallem offline zu betreiben.

    \textbf{3. Remote}
    Hier läuft die Datenbank auf einem externen System und ist über das Netzwerk für unser Programm erreichbar.
    Somit persistent solange auf dem externen System nichts gelöscht wird oder das System nicht beschädigt wird.

    \textbf{Vorteile}
    \begin{itemize}
        \item Datensicherheit
        \item Kapazität
    \end{itemize}

    \textbf{Nachteile}
    \begin{itemize}
        \item Nicht erreichbar ohne Netzwerkverbindung
        \item Braucht externe Infrastruktur (Kosten, Aufwand)
    \end{itemize}

    \textbf{Begründung zur Variante Remote} Diese Variante bringt für uns keinen Mehrwert gegenüber der Embedded-Variante.
    Es wäre eher nur Mehraufwand, der sich aktuell nicht lohnt.

        {\large\bfseries TaskScheduler}

    Für die Anforderung, dass periodisch Dateipfade analysiert werden sollen, war für uns klar dass wir dafür so etwas wie einen
    Task-Scheduler brauchen.
    Und da wir den Daemon genau für das haben ist auch klar, dass diese Tasks am einfachsten über den Daemon gesteuert werden können.
    So ist es auch für die Kommunikation einfacher, da die Resultate der Analyse-Tasks direkt wieder zum Daemon zurückkommuniziert werden können
    und so auch einfach weiterverarbeitet werden können, was vor allem das Speichern in die Datenbank betrifft.

        {\large\bfseries Anwender-Schnittstelle}

    Als Nächstes müssen wir dem Anwender natürlich noch eine Schnittstelle anbieten, über die er Anweisungen/Funktionen von unserem System
    aufrufen kann.
    Dafür gibt es folgende Möglichkeiten:

    \textbf{1. CLI}
    Diese Variante bietet dem Anwender an, über das Kommandozeilen-Interface das System anzuwenden und somit über
    Text-Input auch wieder Text-Output als Resultat zu erhalten.

    \textbf{Vorteile}
    \begin{itemize}
        \item Simpel/Schlicht
    \end{itemize}

    \textbf{Nachteile}
    \begin{itemize}
        \item Schwierigere Anwendung für Anfänger
    \end{itemize}

    \textbf{Begründung CLI} Auch hier haben wir entschieden eine möglichst simple Variante mit geringem initialen Aufwand zu wählen.
    In erster Linie geht es um die Funktionalität, welche auch problemlos mit der CLI-Variante umgesetzt werden kann.
    In der Zukunft können immernoch weitere Schnittstellen hinzugefügt werden, um das System benutzerfreundlicher zu gestalten.

    \textbf{2. GUI}
    Bei der GUI-Variante würde es ein neues Fenster geben z.B. über den Browser oder als Desktop-Applikation,
    worüber der Anwender das System benutzen könnte.
    So wäre es zu Beginn sicherlich etwas einfacher das System zu verstehen und zu verwenden.
    Ausserdem hat man auch eine bessere Übersicht über die Funktionalitäten und kann diese so auch einfacher aufrufen.
    Ebenso können die Resultate übersichtlicher dargestellt werden.

    \textbf{Vorteile}
    \begin{itemize}
        \item Benutzerfreundlichkeit
    \end{itemize}

    \textbf{Nachteile}
    \begin{itemize}
        \item Aufwand
    \end{itemize}

    \textbf{Begründung GUI} Die Variante GUI können wir uns für dieses Projekt auch sehr gut vorstellen.
    Allerdings wäre der Aufwand direkt damit zu starten für uns zu gross, da wir den Fokus erstmal auf die Funktionalitäten legen wollen.
    Aber als Future Work könnte man definitiv noch ein GUI dazubauen.

        {\large\bfseries Schnittstelle CLI $\leftrightarrow$ Daemon}

    Zuletzt braucht es noch eine Schnittstelle zwischen der CLI und dem Daemon,
    um die Anweisungen des Anwenders von der CLI auf den Daemon zu kommunizieren.
    Auch hier machen wir uns Gedanken zu den folgenden Varianten:

    \textbf{1. Rest-Schnittstelle}
    Die Rest-Schnittstelle tauscht über Request/Response zwischen Client und Server Ressourcen aus.
    Dieser Austausch erfolgt mit definierten Formaten (Content-Types) über das HTTP-Protokoll und das Netzwerk.

    \textbf{Vorteile}
    \begin{itemize}
        \item Standardisiert
        \item Robust
        \item CLI und Daemon können auf getrennten Systemen laufen
    \end{itemize}

    \textbf{Nachteile}
    \begin{itemize}
        \item Es muss ein Webservice implementiert werden.
    \end{itemize}

    \textbf{Begründung Rest} Diese Variante passt für uns am Besten, da wir dadurch bereits eine klar strukturierte technische
    Kommunikation haben, die wir relativ einfach nach unserem individuellen Projekt implementieren können.
    Ausserdem ist es eine stabile Schnittstelle, die uns kaum Probleme bereiten sollte, was für uns in diesem Projekt auch wichtig ist.
    Zusätzlich ist die Schnittstelle flexibel und erweiterbar, was es ermöglicht die CLI und den Daemon auch Systemgetrennt zu betreiben.

    \textbf{2. IPC (Inter-process communication)}
    Bei dieser Variante ist das Ziel, zwischen zwei Prozessen (z.B. CLI und Daemon) zu kommunizieren.
    Ein einfacher Weg dafür wäre es sich z.B. ein Directory zu teilen und die CLI könnte dort immer wieder neue Files hineinschreiben,
    welche der Daemon dann nacheinander lesen und verarbeiten würde.

    \textbf{Nachteile}
    \begin{itemize}
        \item Eigenes Format muss für Files definiert werden.
        (muss auch geparst werden)
        \item Daemon und CLI müssen sich immer auf dem selben Computer befinden
        \item Es muss sichergestellt werden, dass die Files in der richtigen Reihenfolge gelesen werden und sich
        Schreiber/Leser von den Files nicht überschneiden
    \end{itemize}

    \textbf{Begründung IPC} Kommt für uns nicht in Frage, da es unflexibel und auch nicht wirklich erweiterbar ist,
    falls die CLI einmal über das Netzwerk mit dem Daemon kommunizieren können sollte.
    Ausserdem ist es aus unserer Sicht auch keine saubere Kommunikation, da es kein standardisiertes Protokoll,
    sowie Format gibt und auch nicht sehr robust ist, was man den Nachteilen entnehmen kann.

    \textbf{3. Sockets}
    Das sind einfache Netzwerk-Sockets, auf welchen binäre Daten geschrieben bzw. gelesen werden.
    Wie gesagt sind diese über das Netzwerk erreichbar und laufen auf entsprechenden Ports des Hosts.
    Welche Bytes an Daten hier geschrieben wird ist völlig offen.

    \textbf{Vorteile}
    \begin{itemize}
        \item Einfache Verwendung und Steuerung
        \item CLI und Daemon können auf getrennten Systemen laufen (Netzwerk)
        \item Out-of-the-Box in java.net package verfügbar
    \end{itemize}

    \textbf{Nachteile}
    \begin{itemize}
        \item Nachrichten-Format muss selbst definiert und geparst werden
    \end{itemize}

    \textbf{Begründung Sockets} Da für uns die Variante Rest noch etwas einfacher erscheint und wir uns auch schon besser
    damit auskennen, haben wir uns gegen Sockets entschieden.
    Dadurch haben wir auch weniger Aufwand mit der Definition und dem Parsen der Kommunikation.

    \subsection{Technologieentscheid}
    In diesem Abschnitt wird erläutert, was wir uns für Gedanken bezüglich Technologien für die verschiedenen Komponenten
    des Systems gemacht haben und wie wir uns entschieden haben.

        {\large\bfseries Datenbank}

    Bezüglich der Komponente Datenbank gibt es einige Varianten, die wir abwägen und eine geeignete für unser Projekt finden müssen.
    Die erste Frage ist \textbf{NoSQL} oder \textbf{SQL}.

    \textbf{1. NoSQL}
    NoSQL bezeichnet nicht-relationale Datenbanken, die flexible Datenmodelle
    (z.B. Dokumente, Key-Value, Graphen) verwenden und für hohe Skalierbarkeit sowie große Datenmengen optimiert sind.

    \textbf{Vorteile}
    \begin{itemize}
        \item Hohe Flexibilität: Kein festes Schema, was dynamische Anpassungen der Datenstruktur ermöglicht.
        \item Einfache Skalierbarkeit: Unterstützt horizontale Skalierung, ideal für große Datenmengen.
        \item Optimiert für spezielle Anwendungsfälle: Verschiedene Modelle wie Dokumente, Key-Value, oder Graphen.
    \end{itemize}

    \textbf{Nachteile}
    \begin{itemize}
        \item Fehlende Standardisierung: Unterschiedliche Implementierungen und keine einheitliche Abfragesprache.
        \item Schwächere Transaktionssicherheit: Viele NoSQL-Datenbanken verzichten auf ACID-Eigenschaften zugunsten der Performance.
        \item Komplexere Abfragen: Nicht so intuitiv wie SQL für relationale Daten.
    \end{itemize}

    \textbf{Begründung NoSQL} Wir sehen für unser Projekt keinen der obengenannten Vorteile als grossen Mehrwertn an.
    Da auch alle Teammitglieder bisher kaum Erfahrungen mit NoSQL-Datenbanken gesammelt haben, entschieden wir uns dagegen.

    \textbf{2. SQL}
    SQL-Datenbanken basieren auf dem relationalen Modell, speichern Daten in Tabellen
    mit definierten Schemata und verwenden die strukturierte Abfragesprache SQL für den Datenzugriff.

    \textbf{Vorteile}
    \begin{itemize}
        \item Standardisierung: Einheitliche Abfragesprache (SQL) und breite Unterstützung.
        \item Datenkonsistenz: Unterstützung von ACID-Eigenschaften für zuverlässige Transaktionen.
        \item Komplexe Abfragen: Leistungsstarke Werkzeuge für relationale Abfragen und Analysen.
    \end{itemize}

    \textbf{Nachteile}
    \begin{itemize}
        \item Wenig flexibel: Feste Schemata erfordern sorgfältige Planung und sind schwer anpassbar.
        \item Begrenzte Skalierbarkeit: Horizontale Skalierung ist oft schwieriger als bei NoSQL.
        \item Leistungsprobleme bei Big Data: Relationale Modelle können ineffizient für große, unstrukturierte Datenmengen sein.
    \end{itemize}

    \textbf{Begründung SQL} Erstens haben alle Teammitglieder bereits viel Erfahrung mit SQL sammeln können und deswegen ist es schonmal intuitiver für uns als NoSQL.
    Dazu war uns auch die Datenkonsistenz wichtig, damit wir mit den relationalen Abfragen, die SQL bietet unsere gespeicherten Daten auch entsprechend gut analysieren können.
    Zum Schluss sehen wir auch die oben aufgelisteten Nachteile nicht als Problem für unser Projekt an.
    Aus diesen Gründen entschieden wir uns für eine SQL-Datenbank.

    Nun wissen wir, dass wir eine Embedded-Datenbank mit SQL wollen.
    Also müssen wir uns noch für eine der folgenden Optionen entscheiden:

    \textbf{1. H2}
    H2 ist eine Java-basierte, leichtgewichtige relationale Datenbank,
    die in Anwendungen eingebettet oder im Servermodus betrieben werden kann.
    Sie bietet hohe Performance, unterstützt SQL-Standards und eignet sich gut für Java-Anwendungen.

    \textbf{Vorteile}
    \begin{itemize}
        \item Java-Integration: Speziell für Java-Anwendungen optimiert, mit JDBC-Unterstützung.
        \item Vielseitigkeit: Kann sowohl als eingebettete Datenbank als auch im Servermodus verwendet werden.
        \item Erweiterte Features: Unterstützt Funktionen wie in-memory-Datenbanken und Multi-Threaded-Betrieb.
    \end{itemize}

    \textbf{Nachteile}
    \begin{itemize}
        \item Nicht für große Workloads: Weniger geeignet für datenintensive Anwendungen.
        \item Java-Abhängigkeit: Funktioniert am besten in Java-Umgebungen, eingeschränkte Nutzung in anderen Ökosystemen.
        \item Begrenzte Persistenzoptionen: Daten können im Speicher verloren gehen, wenn nicht korrekt gesichert.
    \end{itemize}

    \textbf{Begründung H2} Da es praktisch nur in Java-Umgebungen läuft, also weniger standardisiert ist auch bezüglich SQL-Funktionalitäten und nicht für grössere Datenmengen
    ausgelegt ist haben wir uns dagegen entschieden.

    \textbf{2. SQLite}
    SQLite ist eine serverlose, eingebettete relationale Datenbank, die keine separate Konfiguration erfordert.
    Sie speichert Daten in einer einzelnen Datei und ist ideal für kleinere Anwendungen oder lokale Datenpersistenz.

    \textbf{Vorteile}
    \begin{itemize}
        \item Einfachheit: Keine Konfiguration oder separate Serverprozesse erforderlich.
        \item Portabilität: Daten werden in einer einzigen Datei gespeichert, ideal für lokale Persistenz.
        \item Ressourcenschonend: Sehr geringe Anforderungen an Speicher und Rechenleistung.
    \end{itemize}

    \textbf{Nachteile}
    \begin{itemize}
        \item Begrenzte Skalierbarkeit: Nicht ideal für gleichzeitigen Zugriff durch viele Benutzer.
        \item Fehlende Features: Unterstützt nicht alle SQL-Standards wie fortgeschrittene Parallelisierung oder Stored Procedures.
        \item Performance-Einbußen bei großen Datenmengen: Langsamer bei komplexen oder datenintensiven Abfragen.
    \end{itemize}

    \textbf{Begründung SQLite} Vor allem wegen der Einfachheit und vernachlässigbaren Nachteilen haben wir uns für eine
    SQLite Datenbank entschieden.

    {\large\bfseries CLI/Daemon}

    Dann gibt es noch die Komponenten CLI und Daemon, wofür wir gerne eine einheitliche Technologie hätten,
    um es simpel zu halten und auch einfacher gewisse Teile zwischen den beiden Komponenten teilen zu können.

    \textbf{1. Java}
    Java ist eine objektorientierte, plattformunabhängige Programmiersprache,
    die für ihre Stabilität, Performance und breite Unterstützung in der Industrie bekannt ist.
    Sie ist besonders geeignet für komplexe, skalierbare Anwendungen.

    \textbf{Vorteile}
    \begin{itemize}
        \item Performance: Java bietet hohe Laufzeitgeschwindigkeit und Stabilität, ideal für rechenintensive Anwendungen.
        \item Struktur: Starke Typisierung und klare Projektorganisation fördern langfristige Wartbarkeit.
        \item Integration: Unterstützt stabile Verbindungen zu APIs und Modellen, z.B. über REST-Clients oder gRPC.
    \end{itemize}

    \textbf{Nachteile}
    \begin{itemize}
        \item Komplexität: Höherer Entwicklungsaufwand durch Boilerplate-Code und strikte Typisierung.
        \item Eingeschränkte KI-Bibliotheken: KI- und ML-Frameworks sind weniger umfangreich als in Python und oft schwerfälliger zu nutzen.
        \item Langsamere Prototypenentwicklung: Für schnelle Iterationen ist Java weniger geeignet.
    \end{itemize}

    \textbf{Begründung Java} Da für uns die Performance relativ wichtig war und auch hier wieder alle
    Teammitglieder um einiges mehr Erfahrung als mit Python haben, entschieden wir uns für Java.
    Der einzige Punkt, bei dem wir noch zweifelten war die Einschränkung bezüglich KI-Integration,
    welcher aber unserer Meinung nach zu wenig ins Gewicht fiel.
    Zudem sahen wir auch durch Spring-Bibliotheken eine grosse Unterstützung für unsere CLI/Daemon-Architektur.

    \textbf{2. Python}
    Python ist eine einfach zu erlernende, vielseitige Programmiersprache mit einer lesbaren Syntax
    und einer riesigen Anzahl an Bibliotheken, die sie ideal für schnelle Entwicklung
    und datengetriebene Projekte machen.

    \textbf{Vorteile}
    \begin{itemize}
        \item Einfachheit: Kürzere Entwicklungszeit dank klarer Syntax und umfangreicher Standardbibliothek.
        \item KI-Ökosystem: Native Unterstützung für KI-Bibliotheken (z.B. transformers, openai, torch) macht die Integration mit GPT-Modellen mühelos.
        \item Flexibilität: Besonders geeignet für Skripte und Projekte, die schnell iteriert werden müssen.
    \end{itemize}

    \textbf{Nachteile}
    \begin{itemize}
        \item Performance: Kann langsamer sein als Java, besonders bei rechenintensiven Aufgaben.
        \item Fehlende Strenge: Dynamische Typisierung kann bei größeren Projekten zu Wartbarkeitsproblemen führen.
        \item Distributierbarkeit: Python-Anwendungen benötigen oft spezielle Umgebungen oder Pakete, was die Portabilität erschweren kann.
    \end{itemize}

    \textbf{Begründung Python} Hier wäre natürlich die grosse Auswahl und Unterstützung von KI-Bibliotheken ein grosser Vorteil gewesen.
    Allerdings hat dieser Punkt uns zu wenig überzeugt, um uns für Python zu entscheiden.


    \clearpage
    \subsection{Komponenten}\label{subsec:komponenten}


    \begin{figure}[h]
        \centering
        \includegraphics[width=1\textwidth]{assets/comp-diag-tracesentry-v2}
        \caption{UML Komponentendiagramm}
        \label{fig:comp-diag}
    \end{figure}

    \textnormal{Das System besteht aus zwei Hauptkomponenten, welche als eigene Laufzeiteinheiten ausgeführt werden.
    Die CLI wird ad hoc gestartet und dient als Benutzerschnittstelle.
    Der Daemon läuft nach dem Start im Hintergrund und führt periodisch Befehle aus. Ausserdem stellt er der
    CLI eine REST-Schnittstelle zur Verfügung.
    Ein eingebettetes Datenbanksystem speichert die Applikationsdaten.}

    \begin{table}[h!]
        \centering
        \setlength{\leftmargini}{0.4cm}
        \begin{tabular}{|p{2.5cm}|p{5.5cm}|p{3cm}|}
            \hline
            \textbf                       & \textbf{Zweck}                                                    & \textbf{Technologien (primär)} \\
            \hline
            \textbf{Shell}                & {Stellt eine Kommandozeilen-Benutzerschnittstelle zur Verfügung.} & Java, Spring (Shell)           \\
            \hline
            \textbf{Rest Adapter}         & {Stellt den Zugang zur REST-Schnittstelle zur Verfügung}          & Java, Spring (Web)             \\
            \hline
            \textbf{Rest Controller}      & Implementiert die Endpunkte der REST-Schnittstelle                & Java, Spring (Web)             \\
            \hline
            \textbf{Domain Service}       & Applikationslogik                                                 & Java, Spring                   \\
            \hline
            \textbf{Monitoring Scheduler} & Führt Monitoring-Funktionen periodisch aus                        & Java, Spring                   \\
            \hline
            \textbf{Repository}           & Stellt den Zugang zu den persisiterten Daten zur Verfüfung        & Java, Spring (Data)            \\
            \hline
            \textbf{Embedded Database}    & Speichert Applikationsdaten                                       & SQLite                         \\
            \hline
        \end{tabular}
        \caption{Beschreibung der Komponenten}\label{tab:table3}
    \end{table}

    \clearpage

    \section{Prozesse}
    \url{https://www.ganttlab.com} \\
    \url{https://www.hermes.admin.ch/de/projektmanagement/verstehen/ubersicht-hermes/methodenubersicht.html}


    \chapter{Bereitstellung/Integration}

    \begin{figure}[h]
        \centering
        \includegraphics[width=1\textwidth]{assets/DeplDiagram}
        \caption{UML Deploymentdiagramm}
        \label{fig:depl-diag}
    \end{figure}

    Das ganze System befindet sich während der Laufzeit auf dem Host-Gerät des Anwenders.
    Dazu werden zwei separate Jar-Dateien ausgeliefert.
    Die Erste sollte bereits beim Start des Geräts ausgeführt werden und die JVM für den Daemon starten.
    Dieser startet einen Webservice, der REST-Schnittstellen für die Steuerung des Daemons anbietet.
    Dieser REST-Service kommuniziert ausserdem über JDBC mit einem RDBMS, welches in Form von einer einzigen Datei (SQLite)
    in der Daemon-Applikation embedded ist.

    Das zweite Jar sollte dann manuell vom Anwender gestartet werden sobald er Funktionen des Daemons ausführen möchte.
    Dieses Jar startet wiederum eine zweite JVM, welche ein CLI für den Anwender mit bestimmten Kommandos zur Verfügung stellt.
    Diese CLI sendet dann über HTTP die entsprechenden Anfragen an den Daemon, die zur Erfüllung der Anweisungen des Anwenders führen.


    \section{Lizenzierung}


    \section{Installationshandbuch \& Skript}
    In diesem Kapitel sind die Installationsanleitungen für alle unterstützten Plattformen beschrieben, um es
    den Benutzern einfach zu machen unser System auf ihren Geräten zu verwenden.

    Als Vorbedingung muss eine Java Laufzeitumgebung bereits auf dem entsprechenden Gerät installiert sein.

    \subsection{Linux}
    \begin{enumerate}
        \item Durchsuchen Sie das neueste Artefakt, das vom Hauptbranch dieses Repositorys erstellt wurde, und laden Sie die Datei
        \texttt{target/tracesentry-\textless{}version\textgreater{}-submission.zip} auf Ihren Computer herunter.
        \item Entpacken Sie das Archiv in Ihr gewünschtes Installationsverzeichnis für TraceSentry.
        \item Definieren Sie die folgenden Umgebungsvariablen in der Datei \texttt{/etc/environment}:
        \begin{lstlisting}[label={lst:lstlisting-unix-1}]
JAVA_HOME=<absoluter Pfad zum JDK-Ordner>
TRACE_SENTRY_DIR=<absoluter Pfad zum Installationsverzeichnis>
        \end{lstlisting}
        Und fügen Sie die Variable \texttt{TRACE\_SENTRY\_DIR} am Ende der Datei \texttt{/etc/profile} zum \texttt{PATH} hinzu:
        \begin{lstlisting}[label={lst:lstlisting-unix-2}]
PATH=$PATH:$TRACE_SENTRY_DIR
        \end{lstlisting}
        \item Wenn Sie die Inspektionsfunktion nutzen möchten, erstellen Sie einen OpenAI-API-Schlüssel, indem Sie den Anweisungen unter \url{https://platform.openai.com/settings/organization/billing/overview} folgen.
        Setzen Sie anschließend den generierten API-Schlüssel als Umgebungsvariable am Ende der Datei \texttt{/etc/profile}:
        \begin{lstlisting}[label={lst:lstlisting-unix-3}]
export OPENAI_API_KEY=<generierter API-Schlüssel>
        \end{lstlisting}
        Wenn Sie diesen Teil überspringen, haben Sie keinen Zugriff auf die Inspektionsfunktion, aber der Rest wird genauso funktionieren.
        \item Wenn der Daemon bei jedem Systemstart automatisch im Hintergrund gestartet werden soll, können Sie Folgendes in einem Terminal ausführen:
        \begin{lstlisting}[label={lst:lstlisting-unix-4}]
crontab -e
// Fügen Sie die folgende Zeile am Ende der geöffneten Datei hinzu
@reboot PATH=$JAVA_HOME/bin:$PATH $TRACE_SENTRY_DIR/ts run
        \end{lstlisting}
        Speichern Sie dann die Datei.
        \item Nach einem Systemneustart sind Sie bereit, TraceSentry zu verwenden.
    \end{enumerate}

    \subsection{Windows}
    \begin{enumerate}
        \item Durchsuchen Sie das neueste Artefakt, das vom Hauptbranch dieses Repositorys erstellt wurde, und laden Sie die Datei
        \texttt{target/tracesentry-\textless{}version\textgreater{}-submission.zip} auf Ihren Computer herunter.
        \item Entpacken Sie das Archiv in Ihr gewünschtes Installationsverzeichnis für TraceSentry.
        \item Setzen Sie die Umgebungsvariable \texttt{TRACE\_SENTRY\_DIR} via Systemsteuerung oder via PowerShell:
        \begin{lstlisting}[label={lst:lstlisting-windows-1}]
[System.Environment]::SetEnvironmentVariable("TRACE_SENTRY_DIR", "<absoluter Pfad zum Installationsverzeichnis>","User")
        \end{lstlisting}
        \item Damit die CLI korrekt funktioniert, fügen Sie das Installationsverzeichnis zum \texttt{PATH} hinzu:
        \begin{lstlisting}[label={lst:lstlisting-windows-2}]
$currentPath = [System.Environment]::GetEnvironmentVariable("Path", "User")
[System.Environment]::SetEnvironmentVariable("Path", "$currentPath;<absoluter Pfad zum Installationsverzeichnis>","User")
        \end{lstlisting}
        \item Wenn Sie die Inspektionsfunktion nutzen möchten, erstellen Sie einen OpenAI-API-Schlüssel, indem Sie den Anweisungen unter \url{https://platform.openai.com/settings/organization/api-keys} folgen.
        Fügen Sie Guthaben zu Ihrem Konto hinzu, um die OpenAI-API nutzen zu können: \url{https://platform.openai.com/settings/organization/billing/overview}.
        Setzen Sie anschließend den generierten API-Schlüssel als Umgebungsvariable via PowerShell:
        \begin{lstlisting}[label={lst:lstlisting-windows-3}]
[System.Environment]::SetEnvironmentVariable("OPENAI_API_KEY", "<generierter API-Schluessel>","User")
        \end{lstlisting}
        Sollten Sie diesen Teil überspringen, werden Sie keinen Zugriff auf die Inspektionsfunktion haben.
        \item Wenn der Daemon bei jedem Systemstart automatisch im Hintergrund gestartet werden soll, muss die Datei \texttt{ts-daemon.bat} vom Installationsverzeichnis in den Autostart-Ordner kopiert werden:
        \begin{lstlisting}[label={lst:lstlisting-windows-4}]
Copy-Item "$env:TRACE_SENTRY_DIR\ts-daemon.bat" "$env:APPDATA\Microsoft\Windows\Start Menu\Programs\Startup"
        \end{lstlisting}
        Beim nächsten Systemstart wird der Daemon automatisch gestartet.
        Beim ersten Start kann eine Sicherheitswarnung erscheinen, in der Sie eine Checkbox deaktivieren müssen, damit diese in Zukunft nicht mehr erscheint.
        \item Starten Sie das Terminal neu, und Sie sind bereit, TraceSentry zu verwenden.
    \end{enumerate}

    \clearpage

    \subsection{macOS}\label{subsec:macos}
    \begin{enumerate}
        \item Durchsuchen Sie das neueste Artefakt, das vom Hauptbranch dieses Repositorys erstellt wurde, und laden Sie die Datei
        \texttt{target/tracesentry-\textless{}version\textgreater{}-submission.zip} auf Ihren Computer herunter.
        \item Entpacken Sie das Archiv in Ihr gewünschtes Installationsverzeichnis für TraceSentry.
        \item Setzen Sie die Umgebungsvariable \texttt{TRACE\_SENTRY\_DIR} im \texttt{.zprofile} File in ihrem Home-Verzeichnis:
        \begin{lstlisting}[label={lst:lstlisting-mac-1}]
echo 'export TRACE_SENTRY_DIR="<absoluter Pfad zum Installationsverzeichnis>"' >> ~/.zprofile
        \end{lstlisting}
        \item Damit die CLI korrekt funktioniert, fügen Sie das Installationsverzeichnis zum \texttt{PATH} hinzu:
        \begin{lstlisting}[label={lst:lstlisting-mac-2}]
echo 'export PATH="$TRACE_SENTRY_DIR:$PATH"' >> ~/.zprofile
        \end{lstlisting}
        \item Wenn Sie die Inspektionsfunktion nutzen möchten, erstellen Sie einen OpenAI-API-Schlüssel, indem Sie den Anweisungen unter \url{https://platform.openai.com/settings/organization/api-keys} folgen.
        Fügen Sie Guthaben zu Ihrem Konto hinzu, um die OpenAI-API nutzen zu können: \url{https://platform.openai.com/settings/organization/billing/overview}.
        Setzen Sie anschließend den generierten API-Schlüssel als Umgebungsvariable im \texttt{.zprofile} File in ihrem Home-Verzeichnis:
        \begin{lstlisting}[label={lst:lstlisting-mac-3}]
echo 'export OPENAI_API_KEY=<generierter API-Schluessel>' >> ~/.zprofile
        \end{lstlisting}
        Sollten Sie diesen Teil überspringen, werden Sie keinen Zugriff auf die Inspektionsfunktion haben.
        \item Wenn der Daemon bei jedem Systemstart automatisch im Hintergrund gestartet werden soll, passen Sie das \texttt{.zprofile} File in ihrem Home-Verzeichnis wie folgt an:
        \begin{lstlisting}[label={lst:lstlisting-mac-4}]
echo 'export ts run' >> ~/.zprofile
        \end{lstlisting}
        Dies wird als pragmatischste Lösung empfohlen.
        Alternativ können Sie auch \textit{launchd} verwenden.\footnote{\url{https://developer.apple.com/library/archive/documentation/MacOSX/Conceptual/BPSystemStartup/Chapters/CreatingLaunchdJobs.html}}
        \item Starten Sie das Terminal neu, und Sie sind bereit, TraceSentry zu verwenden.
    \end{enumerate}

    \clearpage


    \section{Benutzerhandbuch}
    \label{sec:user-manual}


    \section{Manuelle End-2-End Tests}
    Wie durch das Testkonzept definiert, wurden die End-2-End Tests mehrmals manuell durchgeführt.

    \subsection{Testfälle}

    \begin{table}[h!]
        \centering
        \setlength{\leftmargini}{0.8cm}
        \begin{tabular}{|c|p{10cm}|}
            \hline
            \textbf{ID}                  & E2E-001                                    \\ \hline
            \textbf{Beschreibung}        & Daemon starten und stoppen                 \\ \hline
            \textbf{Vorbedingungen} &
            \begin{itemize}
                \item Daemon läuft nicht
            \end{itemize} \\ \hline
            \textbf{Ablauf} &
            \begin{enumerate}
                \item \begin{verbatim}ts status
                \end{verbatim}
                \item Erwartet: \begin{verbatim}daemon is not running
                \end{verbatim}
                \item \begin{verbatim}ts run
                \end{verbatim}
                \item \begin{verbatim}ts status
                \end{verbatim}
                \item Erwartet: \begin{verbatim}daemon is running
                \end{verbatim}
                \item \begin{verbatim}ts kill
                \end{verbatim}
                \item \begin{verbatim}ts status
                \end{verbatim}
                \item Erwartet: \begin{verbatim}daemon is not running
                \end{verbatim}
            \end{enumerate} \\ \hline
            \textbf{Erwartetes Ergebnis} & Daemon kann gestartet und gestoppt werden. \\ \hline
        \end{tabular}
        \caption{Manueller End-2-End Test E2E-001}\label{tab:e2e-1}
    \end{table}

    \begin{table}[h!]
        \centering
        \setlength{\leftmargini}{0.8cm}
        \begin{tabular}{|c|p{10cm}|}
            \hline
            \textbf{ID}                  & E2E-002                             \\ \hline
            \textbf{Beschreibung}        & Autostart                           \\ \hline
            \textbf{Vorbedingungen} &
            \begin{itemize}
                \item Autostart Konfiguration gem.\ Installationshandbuch
            \end{itemize} \\ \hline
            \textbf{Ablauf} &
            \begin{enumerate}
                \item System neustarten
                \item \begin{verbatim}ts status
                \end{verbatim}
                \item Erwartet: \begin{verbatim}daemon is running
                \end{verbatim}
            \end{enumerate} \\ \hline
            \textbf{Erwartetes Ergebnis} & Daemon wird via Autostart gesartet. \\ \hline
        \end{tabular}
        \caption{Manueller End-2-End Test E2E-002}\label{tab:e2e-2}
    \end{table}

    \begin{table}[h!]
        \centering
        \setlength{\leftmargini}{0.8cm}
        \begin{tabular}{|c|p{10cm}|}
            \hline
            \textbf{ID}                  & E2E-003                                                \\ \hline
            \textbf{Beschreibung}        & Inspect                                                \\ \hline
            \textbf{Vorbedingungen} &
            \begin{itemize}
                \item OPENAI\_API\_KEY Umgebungsvariable gesetzt gem.\ Installationshandbuch
                \item Daemon läuft
                \item Beispiel-Datei unter [PFAD] vorhanden
            \end{itemize} \\ \hline
            \textbf{Ablauf} &
            \begin{enumerate}
                \item \begin{verbatim}ts inspect [PFAD]
                \end{verbatim}
                \item Erwartet:
                \begin{verbatim}
Intended use:
The file ...

Assessment:
...

Recommended to Wipe:
...

Additional recommendations:
...
                \end{verbatim}
            \end{enumerate} \\ \hline
            \textbf{Erwartetes Ergebnis} & Einschätzung und Empfehlung von der KI wird angezeigt. \\ \hline
        \end{tabular}
        \caption{Manueller End-2-End Test E2E-003}\label{tab:e2e-3}
    \end{table}

    \begin{table}[h!]
        \centering
        \setlength{\leftmargini}{0.8cm}
        \begin{tabular}{|c|p{10cm}|}
            \hline
            \textbf{ID}                  & E2E-004                                                                         \\ \hline
            \textbf{Beschreibung}        & Pfad zum Überwachen hinzufügen und entfernen                                    \\ \hline
            \textbf{Vorbedingungen} &
            \begin{itemize}
                \item Daemon läuft
                \item  Der [PFAD] wurde noch nicht hinzugefügt
            \end{itemize} \\ \hline
            \textbf{Ablauf} &
            \begin{enumerate}
                \item \begin{verbatim}ts monitor add [PFAD]
                \end{verbatim}
                \item Erwartet: \begin{verbatim}Successfully added [PFAD]
to the monitoring database.
                \end{verbatim}
                \item \begin{verbatim}ts monitor list
                \end{verbatim}
                \item Erwartet: Der hinzugefügte Pfad wird aufgelistet.
                [ID] des Pfades notieren.
                \item \begin{verbatim}ts monitor remove [ID]
                \end{verbatim}
                \item Erwartet: \begin{verbatim}Successfully removed path with ID [ID]
from the monitoring database.
                \end{verbatim}
                \item \begin{verbatim}ts monitor list
                \end{verbatim}
                \item Erwartet: Der gelöschte Pfad wird nicht mehr aufgelistet.
            \end{enumerate} \\ \hline
            \textbf{Erwartetes Ergebnis} & Ein Pfad kann ohne Fehler hinzugefügt und anschliessend wieder entfernt werden. \\ \hline
        \end{tabular}
        \caption{Manueller End-2-End Test E2E-004}\label{tab:e2e-4}
    \end{table}

    \begin{table}[h!]
        \centering
        \setlength{\leftmargini}{0.8cm}
        \begin{tabular}{|c|p{10cm}|}
            \hline
            \textbf{ID}                  & E2E-005                                                        \\ \hline
            \textbf{Beschreibung}        & Pfad zum Überwachen mit Mode und ohne Unterordner hinzufügen.  \\ \hline
            \textbf{Vorbedingungen} &
            \begin{itemize}
                \item Daemon läuft
                \item  Der [PFAD] wurde noch nicht hinzugefügt
            \end{itemize} \\ \hline
            \textbf{Ablauf} &
            \begin{enumerate}
                \item \begin{verbatim}ts monitor add [PFAD]
--mode log --no-subdirs
                \end{verbatim}
                \item Erwartet: \begin{verbatim}Successfully added [PFAD] to the
monitoring database.
                \end{verbatim}
                \item \begin{verbatim}ts monitor list
                \end{verbatim}
                \item Erwartet: Pfad wird mit mode=LOG und no-subdirs=true aufgelistet.
            \end{enumerate} \\ \hline
            \textbf{Erwartetes Ergebnis} & Ein Pfad kann mit den gewünschten Optionen hinzugefügt werden. \\ \hline
        \end{tabular}
        \caption{Manueller End-2-End Test E2E-005}\label{tab:e2e-5}
    \end{table}

    \begin{table}[h!]
        \centering
        \setlength{\leftmargini}{0.8cm}
        \begin{tabular}{|c|p{10cm}|}
            \hline
            \textbf{ID}                  & E2E-006                                                               \\ \hline
            \textbf{Beschreibung}        & Pfad zum Überwachen mit Regex-Pattern hinzufügen.                     \\ \hline
            \textbf{Vorbedingungen} &
            \begin{itemize}
                \item Daemon läuft
                \item  Der [PFAD] wurde noch nicht hinzugefügt
            \end{itemize} \\ \hline
            \textbf{Ablauf} &
            \begin{enumerate}
                \item \begin{verbatim}ts monitor add [PFAD] --mode pattern
--pattern ^ts_.*_ts$
                \end{verbatim}
                \item Erwartet: \begin{verbatim}Successfully added [PFAD] to the
monitoring database.
                \end{verbatim}
                \item \begin{verbatim}ts monitor list
                \end{verbatim}
                \item Erwartet: Pfad wird mit pattern=\begin{verbatim}^ts_.*_ts$
                \end{verbatim} aufgelistet.
            \end{enumerate} \\ \hline
            \textbf{Erwartetes Ergebnis} & Ein Pfad kann mit einem gewünschten Regex-Pattern hinzugefügt werden. \\ \hline
        \end{tabular}
        \caption{Manueller End-2-End Test E2E-006}\label{tab:e2e-6}
    \end{table}

    \begin{table}[h!]
        \centering
        \setlength{\leftmargini}{0.8cm}
        \begin{tabular}{|c|p{10cm}|}
            \hline
            \textbf{ID} & E2E-007 \\ \hline
            \textbf{Beschreibung} & Snapshots generieren lassen und vergleichen. \\ \hline
            \textbf{Vorbedingungen} &
            \begin{itemize}
                \item Daemon läuft
                \item Der [PFAD] wurde noch nicht hinzugefügt.
                (Empfohlen: ein nicht zu tiefer Pfad, damit die Snapshots schneller generiert werden)
            \end{itemize} \\ \hline
            \textbf{Ablauf} &
            \begin{enumerate}
                \item \begin{verbatim}ts monitor add [PFAD] && ts monitor list
                \end{verbatim}
                \item Erwartet: Auflistung des zu überwachenden Pfads, sowie dessen [ID].
                \item \begin{verbatim}ts kill && ts run
                \end{verbatim}
                \item Warten bis Snapshot in Datenbank vorhanden ist.
                Mit nachfolgendem Schritt überprüfen.
                \item \begin{verbatim}ts snapshots list [ID]
                \end{verbatim}
                \item Erwartet: Liste mit genau 1 Snapshot.
                \item Eine Datei test.log in [PFAD] erstellen und mit Inhalt füllen.
                \item \begin{verbatim}ts kill && ts run
                \end{verbatim}
                \item Warten bis zweiter Snapshot in Datenbank vorhanden ist.
                Mit nachfolgendem Schritt überprüfen.
                \item \begin{verbatim}ts snapshots list [ID]
                \end{verbatim}
                \item Erwartet: Liste mit genau 2 Snapshots.
                \item \begin{verbatim}ts snapshots compare [ID]
                \end{verbatim}
                \item Erwartet: Unterschied in der Datei test.log wird aufgelistet.
                \item \begin{verbatim}ts kill && ts run
                \end{verbatim}
                \item Warten bis in Datenbank genau 3 Snapshots vorhanden sind.
                (siehe oben)
                \item \begin{verbatim}ts kill && ts run
                \end{verbatim}
                \item Warten bis in Datenbank genau 4 Snapshots vorhanden sind.
                (siehe oben)
                \item Den Inhalte der Datei test.log ändern.
                \item \begin{verbatim}ts kill && ts run
                \end{verbatim}
                \item Warten bis in Datenbank genau 5 Snapshots vorhanden sind.
                (siehe oben)
                \item \begin{verbatim}ts snapshots compare [ID]
                \end{verbatim}
                \item Erwartet: Unterschied in der Datei test.log wird aufgelistet.
                \item test.log löschen.
                \item \begin{verbatim}ts kill && ts run
                \end{verbatim}
                \item Warten bis in Datenbank genau 6 Snapshots vorhanden sind.
                \item \begin{verbatim}ts snapshots compare [ID]
                \end{verbatim}
                \item Erwartet: Löschung der Datei test.log wird aufgelistet.
            \end{enumerate} \\ \hline
            \textbf{Erwartetes Ergebnis} & Snapshots werden generiert und drei verschiedenen Zeitintervalle verglichen.
            Erstellung, Änderung und Löschung einer Datei werden erkannt. \\ \hline
        \end{tabular}
        \caption{Manueller End-2-End Test E2E-007}\label{tab:e2e-7}
    \end{table}

    \begin{table}[h!]
        \centering
        \setlength{\leftmargini}{0.8cm}
        \begin{tabular}{|c|p{10cm}|}
            \hline
            \textbf{ID}                  & E2E-008                                            \\ \hline
            \textbf{Beschreibung}        & Search (Cache- und Log-Dateien)                    \\ \hline
            \textbf{Vorbedingungen} &
            \begin{itemize}
                \item Daemon läuft
                \item Beispiel-Verzeichnis unter [PFAD] vorhanden
            \end{itemize} \\ \hline
            \textbf{Ablauf} &
            \begin{enumerate}
                \item \begin{verbatim}ts search [PFAD]
                \end{verbatim}
                \item Erwartet: Auflistung der Inhalte unter [PFAD] welche \("\)cache\("\) oder \("\)log\("\) enthalten.
            \end{enumerate} \\ \hline
            \textbf{Erwartetes Ergebnis} & Auflistung von Dateiinhalten in einem Verzeichnis. \\ \hline
        \end{tabular}
        \caption{Manueller End-2-End Test E2E-008}\label{tab:e2e-8}
    \end{table}

    \begin{table}[h!]
        \centering
        \setlength{\leftmargini}{0.8cm}
        \begin{tabular}{|c|p{10cm}|}
            \hline
            \textbf{ID}                  & E2E-009                          \\ \hline
            \textbf{Beschreibung}        & Leeren und Löschen einer Datei   \\ \hline
            \textbf{Vorbedingungen} &
            \begin{itemize}
                \item Datei unter [PFAD] ist nicht geschützt. (z.B. durch Berechtigungen)
                \item Daemon läuft
            \end{itemize} \\ \hline
            \textbf{Ablauf} &
            \begin{enumerate}
                \item \begin{verbatim}ts wipe [PFAD]
                \end{verbatim}
                \item Erwartet: \begin{verbatim}Successfully cleared file.
                \end{verbatim}
                \item Erwartet: Datei wurde geleert
                \item \begin{verbatim}ts wipe [PFAD] --remove
                \end{verbatim}
                \item Erwartet: \begin{verbatim}Successfully removed file.
                \end{verbatim}
                \item Erwartet: Datei wurde gelöscht
            \end{enumerate} \\ \hline
            \textbf{Erwartetes Ergebnis} & Datei wird geleert und gelöscht. \\ \hline
        \end{tabular}
        \caption{Manueller End-2-End Test E2E-009}\label{tab:e2e-9}
    \end{table}

    \subsection{Testergebnisse}
    \begin{table}[h!]
        \centering
        \setlength{\leftmargini}{0.4cm}
        \begin{tabular}{|c|c|c|c|}
            \hline
            \textbf{Datum} & \textbf{Betriebssystem} & \textbf{Testfall} & \textbf{Ergebnis} \\ \hline
            26.12.2024     & Windows 10              & E2E-001           & Erfolgreich       \\ \hline
            26.12.2024     & Debian 12               & E2E-001           & Erfolgreich       \\ \hline
            26.12.2024     & macOS Sequoia 15.2      & E2E-001           & Erfolgreich       \\ \hline
            26.12.2024     & Windows 10              & E2E-002           & Erfolgreich       \\ \hline
            26.12.2024     & Debian 12               & E2E-002           & Erfolgreich       \\ \hline
            26.12.2024     & macOS Sequoia 15.2      & E2E-002           & Erfolgreich       \\ \hline
            26.12.2024     & Windows 10              & E2E-003           & Erfolgreich       \\ \hline
            26.12.2024     & Debian 12               & E2E-003           & Erfolgreich       \\ \hline
            26.12.2024     & macOS Sequoia 15.2      & E2E-003           & Erfolgreich       \\ \hline
            26.12.2024     & Windows 10              & E2E-004           & Erfolgreich       \\ \hline
            26.12.2024     & Debian 12               & E2E-004           & Erfolgreich       \\ \hline
            26.12.2024     & macOS Sequoia 15.2      & E2E-004           & Erfolgreich       \\ \hline
            26.12.2024     & Windows 10              & E2E-005           & Erfolgreich       \\ \hline
            26.12.2024     & Debian 12               & E2E-005           & Erfolgreich       \\ \hline
            26.12.2024     & macOS Sequoia 15.2      & E2E-005           & Erfolgreich       \\ \hline
            26.12.2024     & Windows 10              & E2E-006           & Erfolgreich       \\ \hline
            26.12.2024     & Debian 12               & E2E-006           & Erfolgreich       \\ \hline
            26.12.2024     & macOS Sequoia 15.2      & E2E-006           & Erfolgreich       \\ \hline
            26.12.2024     & Windows 10              & E2E-007           & Erfolgreich       \\ \hline
            26.12.2024     & Debian 12               & E2E-007           & Erfolgreich       \\ \hline
            26.12.2024     & macOS Sequoia 15.2      & E2E-007           & Erfolgreich       \\ \hline
            26.12.2024     & Windows 10              & E2E-008           & Erfolgreich       \\ \hline
            26.12.2024     & Debian 12               & E2E-008           & Erfolgreich       \\ \hline
            26.12.2024     & macOS Sequoia 15.2      & E2E-008           & Erfolgreich       \\ \hline
            26.12.2024     & Windows 10              & E2E-009           & Erfolgreich       \\ \hline
            26.12.2024     & Debian 12               & E2E-009           & Erfolgreich       \\ \hline
            26.12.2024     & macOS Sequoia 15.2      & E2E-009           & Erfolgreich       \\ \hline

        \end{tabular}
        \caption{Manuelle End-2-End Testergebnisse}\label{tab:e2e-results}
    \end{table}


    \clearpage


    \section{Messungen (Performanztests)}\label{sec:performanztests}
    Um eine Aussage über die Performanz unseres Systems zu machen, haben wir einige Performanztests durchgeführt.
    Diese dienen lediglich als Indikator und sind nicht repräsentativ für alle möglichen Szenarien.
    Es werden nur Kernfunktionen getestet, die Performanz kritisch sein könnten.

    \subsection{Suchfunktion}\label{subsec:testduchfuhrung}
    Es wird im Modus FULL (Cache- und Logdateien) im spezifizierten Pfad nach Dateien gesucht.

    \subsubsection{Verwendete Umgebungsangaben und Metriken}\label{subsubsec:search-perftest-metrics-title}
    \begin{table}[h!]
        \centering
        \setlength{\leftmargini}{0.8cm}
        \begin{tabular}{|p{7cm}|p{7cm}|}
            \hline
            \textbf{System}                                            & Betriebssystem und Architektur                                                  \\ \hline
            \textbf{Pfad}                                              & Verzeichnis, in dem gesucht wird                                                \\ \hline
            \textbf{Anz. Dateien im Pfad}                              & Anzahl Dateien im Pfad (mit allen Unterverzeichnissen)                          \\ \hline
            \textbf{Anz. Verzeichnisse im Pfad}                        & Anzahl Unterverzeichnisse                                                       \\ \hline
            \textbf{Anz. Ebenen \newline des Baumes relevanter Knoten} & Anzahl Ebenen im konstruierten Baum aller gefundenen Dateien und Verzeichnissen \\ \hline
            \textbf{Anz. Knoten \newline des Baumes relevanter Knoten} & Anzahl Knoten im konstruierten Baum aller gefundenen Dateien und Verzeichnissen \\ \hline
            \textbf{Gefundene Dateien}                                 & Anzahl Dateien, die gefunden wurden                                             \\ \hline
            \textbf{Dauer (Stichprobenmittel)}                        & Mittelwert der Dauer in Millisekunden aus mehreren Stichproben                   \\ \hline
        \end{tabular}
        \caption{Beschreibung Umgebungsangaben und Metriken Suchfunktion-Performanztest}\label{tab:perf-search-metrics}
    \end{table}

    \newpage

    \subsubsection{Ergebnisse}
    \begin{table}[h!]
        \centering
        \setlength{\leftmargini}{0.8cm}
        \begin{tabular}{|p{7cm}|p{5cm}|}
            \hline
            \textbf{System}                                            & Windows 11--10.0 / amd64 \\ \hline
            \textbf{Pfad}                                              & C:\textbackslash Windows \\ \hline
            \textbf{Anz. Dateien im Pfad}                              & 188'428                  \\ \hline
            \textbf{Anz. Verzeichnisse im Pfad}                        & 51'184                   \\ \hline
            \textbf{Anz. Ebenen \newline des Baumes relevanter Knoten} & 14                       \\ \hline
            \textbf{Anz. Knoten \newline des Baumes relevanter Knoten} & 54'682                   \\ \hline
            \textbf{Gefundene Dateien}                                 & 3'455                    \\ \hline
            \textbf{Dauer (Stichprobenmittel)}                        & 8'800ms                  \\ \hline
        \end{tabular}
        \caption{Performanztest Suche WIN-1}\label{tab:perf-search-win-1}
    \end{table}

    \begin{table}[h!]
        \centering
        \setlength{\leftmargini}{0.8cm}
        \begin{tabular}{|p{7cm}|p{5cm}|}
            \hline
            \textbf{System}                                            & Windows 11--10.0 / amd64       \\ \hline
            \textbf{Pfad}                                              & C:\textbackslash Program Files \\ \hline
            \textbf{Anz. Dateien im Pfad}                              & 66'386                         \\ \hline
            \textbf{Anz. Verzeichnisse im Pfad}                        & 8'925                          \\ \hline
            \textbf{Anz. Ebenen \newline des Baumes relevanter Knoten} & 20                             \\ \hline
            \textbf{Anz. Knoten \newline des Baumes relevanter Knoten} & 10'109                         \\ \hline
            \textbf{Gefundene Dateien}                                 & 1'183                          \\ \hline
            \textbf{Dauer (Stichprobenmittel)}                        & 800ms                          \\ \hline
        \end{tabular}
        \caption{Performanztest Suche WIN-2}\label{tab:perf-search-win-2}
    \end{table}

    \begin{table}[h!]
        \centering
        \setlength{\leftmargini}{0.8cm}
        \begin{tabular}{|p{7cm}|p{5cm}|}
            \hline
            \textbf{System}                                            & Mac OS X 15.2 / aarch64 \\ \hline
            \textbf{Pfad}                                              & /Library/Logs/          \\ \hline
            \textbf{Anz. Dateien im Pfad}                              & 229                     \\ \hline
            \textbf{Anz. Verzeichnisse im Pfad}                        & 89                      \\ \hline
            \textbf{Anz. Ebenen \newline des Baumes relevanter Knoten} & 9                       \\ \hline
            \textbf{Anz. Knoten \newline des Baumes relevanter Knoten} & 120                     \\ \hline
            \textbf{Gefundene Dateien}                                 & 31                      \\ \hline
            \textbf{Dauer (Stichprobenmittel)}                        & 6.6ms                   \\ \hline
        \end{tabular}
        \caption{Performanztest Suche MAC-1}\label{tab:perf-search-mac-1}
    \end{table}

    \begin{table}[h!]
        \centering
        \setlength{\leftmargini}{0.8cm}
        \begin{tabular}{|p{7cm}|p{5cm}|}
            \hline
            \textbf{System}                                            & Mac OS X 15.2 / aarch64 \\ \hline
            \textbf{Pfad}                                              & /Library/Caches/        \\ \hline
            \textbf{Anz. Dateien im Pfad}                              & 677                     \\ \hline
            \textbf{Anz. Verzeichnisse im Pfad}                        & 8                       \\ \hline
            \textbf{Anz. Ebenen \newline des Baumes relevanter Knoten} & 3                       \\ \hline
            \textbf{Anz. Knoten \newline des Baumes relevanter Knoten} & 6                       \\ \hline
            \textbf{Gefundene Dateien}                                 & 0                       \\ \hline
            \textbf{Dauer (Stichprobenmittel)}                        & 0.6ms                   \\ \hline
        \end{tabular}
        \caption{Performanztest Suche MAC-2}\label{tab:perf-search-mac-2}
    \end{table}

    \begin{table}[h!]
        \centering
        \setlength{\leftmargini}{0.8cm}
        \begin{tabular}{|p{7cm}|p{5cm}|}
            \hline
            \textbf{System}                                            & Linux 6.1.0-28 / amd64    \\ \hline
            \textbf{Pfad}                                              & /opt/idea-IU-242.22855.74 \\ \hline
            \textbf{Anz. Dateien im Pfad}                              & 2248                      \\ \hline
            \textbf{Anz. Verzeichnisse im Pfad}                        & 793                       \\ \hline
            \textbf{Anz. Ebenen \newline des Baumes relevanter Knoten} & 10                        \\ \hline
            \textbf{Anz. Knoten \newline des Baumes relevanter Knoten} & 806                       \\ \hline
            \textbf{Gefundene Dateien}                                 & 13                        \\ \hline
            \textbf{Dauer (Stichprobenmittel)}                        & 21ms                      \\ \hline
        \end{tabular}
        \caption{Performanztest Suche LIN-1}\label{tab:perf-search-lin-1}
    \end{table}

    \begin{table}[h!]
        \centering
        \setlength{\leftmargini}{0.8cm}
        \begin{tabular}{|p{7cm}|p{5cm}|}
            \hline
            \textbf{System}                                            & Linux 6.1.0-28 / amd64 \\ \hline
            \textbf{Pfad}                                              & /home/luca             \\ \hline
            \textbf{Anz. Dateien im Pfad}                              & 47'3915                \\ \hline
            \textbf{Anz. Verzeichnisse im Pfad}                        & 9'8549                 \\ \hline
            \textbf{Anz. Ebenen \newline des Baumes relevanter Knoten} & 29                     \\ \hline
            \textbf{Anz. Knoten \newline des Baumes relevanter Knoten} & 104'448                \\ \hline
            \textbf{Gefundene Dateien}                                 & 5'429                  \\ \hline
            \textbf{Dauer (Stichprobenmittel)}                        & 2'663ms                \\ \hline
        \end{tabular}
        \caption{Performanztest Suche LIN-2}\label{tab:perf-search-lin-2}
    \end{table}

    \clearpage

    \subsection{Monitoring}\label{subsec:monitoring)}
    Es werden mehrere Pfade über einen längeren Zeitraum (simuliert) überwacht bzw.\ Snapshots erstellt.

    \subsubsection{Verwendete Umgebungsangaben und Metriken}\label{subsubsec:monitoring-perftest-metrics-title}
    \begin{table}[h!]
        \centering
        \setlength{\leftmargini}{0.8cm}
        \begin{tabular}{|p{7cm}|p{7cm}|}
            \hline
            \textbf{System}                                               & Betriebssystem und Architektur                                             \\ \hline
            \textbf{Pfade}                                                & Verzeichnisse, die überwacht werden                                        \\ \hline
            \textbf{Anz. Erstellte Snapshots}                             & Anzahl erstellter Snapshots                                                \\ \hline
            \textbf{Anz. Erstellte Knoten}                                & Anzahl erstellter Knoten in der Datenbank                                  \\ \hline
            \textbf{Benötigte Zeit}                                       & Gesamte Zeit, die benötigt wurde, um alle Snapshots zu erstellen           \\ \hline
            \textbf{Durchschnittliche Dauer zum Erstellen eines Snapshots} & Durchschnittliche Dauer, die benötigt wurde, um einen Snapshot zu erstellen \\ \hline
        \end{tabular}
        \caption{Beschreibung Umgebungsangaben und Metriken Monitoring-Performanztest}\label{tab:monitoring-perftest-metrics}
    \end{table}

    \subsubsection{Ergebnisse}
    \begin{table}[h!]
        \centering
        \setlength{\leftmargini}{0.8cm}
        \begin{tabular}{|p{5cm}|p{10cm}|}
            \hline
            \textbf{System}                                               & Windows 11--10.0 / amd64 \\ \hline
            \textbf{Pfade} &
            \begin{itemize}
                \item C:\textbackslash Users\textbackslash Luca\textbackslash AppData\textbackslash Roaming\textbackslash discord\textbackslash Cache
                \item C:\textbackslash Users\textbackslash Luca\textbackslash AppData\textbackslash Roaming\textbackslash discord\textbackslash logs
                \item C:\textbackslash Users\textbackslash Luca\textbackslash AppData\textbackslash Roaming\textbackslash Docker Desktop\textbackslash Cache
                \item C:\textbackslash Users\textbackslash Luca\textbackslash AppData\textbackslash Roaming\textbackslash Microsoft
                \item C:\textbackslash Users\textbackslash Luca\textbackslash AppData\textbackslash Roaming\textbackslash NVIDIA
                \item C:\textbackslash ProgramData\textbackslash ASUS
                \item C:\textbackslash ProgramData\textbackslash Package Cache
                \item C:\textbackslash ProgramData\textbackslash Corsair
                \item C:\textbackslash ProgramData\textbackslash NVIDIA Corporation
                \item C:\textbackslash ProgramData\textbackslash LGHUB
            \end{itemize}
            \\ \hline
            \textbf{Anz. Erstellte Snapshots}                             & 7'200                    \\ \hline
            \textbf{Anz. Erstellte Knoten}                                & 583'920                  \\ \hline
            \textbf{Benötigte Zeit}                                       & 8min                     \\ \hline
            \textbf{Durchschnittliche Dauer zum Erstellen eines Snapshots} & 670ms                    \\ \hline
        \end{tabular}
        \caption{Performanztest Monitoring WIN}\label{tab:perf-monitoring-win}
    \end{table}

    \begin{table}[h!]
        \centering
        \setlength{\leftmargini}{0.8cm}
        \begin{tabular}{|p{5cm}|p{10cm}|}
            \hline
            \textbf{System}                                               & Mac OS X 15.2 / aarch64 \\ \hline
            \textbf{Pfade} &
            \begin{itemize}
                \item /Library/Logs/
                \item /Library/Caches/
                \item /Library/Google
                \item /Library/Apple
                \item /Library/OSAnalytics
                \item /Library/Filesystems
                \item /Library/Bluetooth
                \item /Users/janicscherer/IdeaProjects
                \item /Users/janicscherer/bin
                \item /tmp
            \end{itemize}
            \\ \hline
            \textbf{Anz. Erstellte Snapshots}                             & 7'200                   \\ \hline
            \textbf{Anz. Erstellte Knoten}                                & 9'079'920               \\ \hline
            \textbf{Benötigte Zeit}                                       & 10min                   \\ \hline
            \textbf{Durchschnittliche Dauer zum Erstellen eines Snapshots} & 914ms                   \\ \hline
        \end{tabular}
        \caption{Performanztest Monitoring MAC}\label{tab:perf-monitoring-mac}
    \end{table}

    \begin{table}[h!]
        \centering
        \setlength{\leftmargini}{0.8cm}
        \begin{tabular}{|p{5cm}|p{10cm}|}
            \hline
            \textbf{System}                                               & Linux 6.1.0-28 / amd64 \\ \hline
            \textbf{Pfade} &
            \begin{itemize}
                \item /home/luca/tracesentry-1.0.2
                \item /opt/idea-IU-242.22855.74
                \item /opt/vivaldi
                \item /tmp
                \item /etc
                \item /usr/local
                \item /usr/share/vim
                \item /dev
                \item /opt/az/lib/python3.12/email
                \item /opt/android-studio
            \end{itemize}
            \\ \hline
            \textbf{Anz. Erstellte Snapshots}                             & 7'200                  \\ \hline
            \textbf{Anz. Erstellte Knoten}                                & 1'717'920              \\ \hline
            \textbf{Benötigte Zeit}                                       & 2min                   \\ \hline
            \textbf{Durchschnittliche Dauer zum Erstellen eines Snapshots} & 173ms                  \\ \hline
        \end{tabular}
        \caption{Performanztest Monitoring LIN}\label{tab:perf-monitoring-lin}
    \end{table}


    \chapter{Fazit}


    \section{Diskussion}

    \subsection{Ausblick auf die Zukunft}


    \section{Zusammenfassung}


    \section{Zukünftige Arbeiten}\label{sec:zukunftigearbeiten}
    \url{https://doi.org/10.1145/3664811}


    \chapter{Glossar}


    \chapter{Index}


    \chapter{Bibliografie}


    \chapter{Anhang}


    \section{Facsimile der Projektbeschreibung}


    \section{Erklärung zur Urheberschaft}

\end{document}
